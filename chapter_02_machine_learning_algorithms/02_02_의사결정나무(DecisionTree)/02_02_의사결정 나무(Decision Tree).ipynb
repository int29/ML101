{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0722091",
   "metadata": {},
   "source": [
    "## 03.의사결정 나무(Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db51eb",
   "metadata": {},
   "source": [
    "### (1) 의사결정나무 이해하기\n",
    "\n",
    "의사결정 나무(Decision Tree) 알고리즘은 주어진 학습데이터를 트리구조의 모형으로 만들어 데이터를 분류하거나 수치를 예측하는 알고리즘을 말한다. <span style=\"font-size:70%\">[1]</span> \n",
    "\n",
    "대부분의 머신러닝 알고리즘이 결과를 도출하기 까지의 과정 및 해석이 불가능한 블랙박스 모형(Blackbox model)인데 반해,  의사결정트리(Decision Tree)는 결과를 도출하는 과정을 직관적으로 확인하고 해석할 수 있어 굉장히 범용적으로 사용가능하다. 동시에 준수한 성능을 보이기 때문에 굉장히 많이 사용하는 머신러닝 알고리즘이다. <span style=\"font-size:70%\">[2]</span> \n",
    "\n",
    "알고리즘에 대해 깊이 들어가기 전 트리(Tree)가 무엇인지 그리고 학습에 필요한 용어들에 대해서 간단하게 살펴보고 넘어가자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1fa1f9",
   "metadata": {},
   "source": [
    "### (1-1). 트리구조의 이해\n",
    "\n",
    "트리구조는 계층적(hierarchy)인 구조를 갖는 정보를 표현하는 하나의 자료구조이다. 크게 그래프구조라는 자료구조의 한 종류이기 때문에 노드(Node)와 엣지(Edge)로 자료를 계층적으로 표현한다. \n",
    "\n",
    "쉽게 생각해 노드는 데이터를 담는 그릇이고, 각 노드 끼리의 어떻게 연결되었는지에 대한 관계를 엣지로 표현할 수 있다. 이 모습이 나무를 거꾸로 메달아 놓은것과 비슷하다고 하여 트리구조라 부른다.\n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_machine_learning_algorithms/02_02_%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4(DecisionTree)/img/03_01.png?raw=true\" width=600>\n",
    "    <p>[그림03_01]</p>\n",
    "</div>\n",
    "\n",
    "의사결정 나무는 트리구조 중 이진트리(binary tree)이다. 이진트리는 하나의 부모노드(parents node)가 반드시 2개 이하의 자식노드(children node)를 갖는 트리를 말한다. 이 때 모든 데이터가 존재하는 가장 첫번째 노드를 뿌리노드(root node)라고 부르며 뿌리노드 부터 자식노드로 계속 데이터가 분할된다. 이 때 더이상 자식노드가 없는 가장 마지막 노드를 잎노드(leaf node)라 부른다. 또한 각 노드의 가로 층을 레벨(Level)이라 부르며 가장 높은 레벨을 트리의 깊이(Depth)라고 부른다.<span style=\"font-size:70%\">[3][4]</span> \n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_machine_learning_algorithms/02_02_%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4(DecisionTree)/img/03_02.png?raw=true\" width=700>\n",
    "    <p>[그림03_02]</p>\n",
    "</div>\n",
    "\n",
    "> 구체적인 그래프 구조 및 트리구조에 대하여 확인이 필요하면, 그래프구조 > 트리구조 로 구글링 혹은 아래 2개의 무료 공개수업에서 학습할 수 있다.<br>* 자료구조(2018),조행래,영남대학교,K-Mooc (http://www.kmooc.kr/courses/course-v1:YeungnamUnivK+YU216002+2018_01/about)<br>* 이산수학(2016),원성현,부산가톨릭대학교,KOCW http://www.kocw.net/home/cview.do?cid=2df3e8cf09399ca3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f38d6",
   "metadata": {},
   "source": [
    "### (1-2). 의사결정나무 학습알고리즘 이해 \n",
    "### : 정보이득을 최대화 시키는 규칙으로 나눈다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa25343",
   "metadata": {},
   "source": [
    "우리가 스무고개를 통해서 퀴즈를 맞추는 상황을 상상해보자. \n",
    "\n",
    "<hr>\n",
    "Q) \"살아있나요?\"\n",
    "A) \"네\"\n",
    "\n",
    "Q) \"인간인가요?\"\n",
    "A) \"아니요\"\n",
    "\n",
    "Q) \"털이 있나요?\"\n",
    "A) \"네\"\n",
    "\n",
    "Q) \"애완동물인가요\"\n",
    "A) \"네\"\n",
    "\n",
    "Q) \"강아지 인가요?\"\n",
    "A) \"네\"\n",
    "<hr>\n",
    "\n",
    "위 스무고개를 의사결정 모델로 구현하면 아래와 같다. 스무고개에서는 처음에는 굉장히 나이브한 질문을 진행하고, 각 질문은 범위를 좁혀나가는 역할을 진행한다. 이렇게 정보를 구체화하다 정답을 도출하게 된다. 각 질문과 질문에 따라 분류되는 추정들은 노드에 저장되고, 아래로 내려갈수록 점점 정보가 구체화되고 종국에는 강아지라는 정답을 찾는 전체 과정이 트리모델로 표현된다.<span style=\"font-size:70%\">[5]</span> \n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_machine_learning_algorithms/02_02_%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4(DecisionTree)/img/03_03.png?raw=true\" width=400>\n",
    "    <p>[그림03_03]</p>\n",
    "</div>\n",
    "\n",
    "의사결정 나무 알고리즘 또한 스무고개와 동일하다. 알고리즘의 목표는 훈련데이터를 트리구조로 표현하는 모델을 만들고 이 모델을 통해 예측값을 만드는것이다. 스무고개에서 점점 정보를 구체화했던 전략은 사실은 각 질문은 정보량이 가장 커질수 있는 방향으로 질문하는것을 의미하며, 각 단계를 거쳐 구체화되는 현상은 정보의 양이 점차 증가한 것으로 표현할 수 있다. 이처럼 의사결정나무 알고리즘도 각 노드에서 정보이득(Information Gain)이 가장 커질 수 있는 규칙을 탐색하고 데이터를 나누며 정답을 구체화 해나간다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac4a005",
   "metadata": {},
   "source": [
    "### (1-3) 데이터의 정보이득을 평가하는 수치적 평가지표  : 지니불순도, 엔트로피\n",
    "\n",
    "의사결정나무 알고리즘에서는 데이터의 정보이득을 평가하기 위한 지표로 지니 불순도(Gini impurity)와 엔트로피(Entropy)를 주로 활용한다.\n",
    "\n",
    "### 지니불순도(Gini impurity)\n",
    "\n",
    "지니불순도(Gini impurity)는 쉽게 어떤 그룹이 한가지로 구성되어 있을 수록(순수할수록) 정보량이 많다는것이다. 이 컨셉은 꾀나 직관적인데 아래그림에서 양끝단으로 갈수록 판단하기에 수월하고 중앙으로 갈수록 점점 판단하기가 애매해지는 것을 확인할 수 있다. 이처럼 지니불순도는 정보라는것은 불순도가 낮을수록 높아진다는 것을 표현한 것을 의미한다.\n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_machine_learning_algorithms/02_02_%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4(DecisionTree)/img/03_04.png?raw=true\" width=400>\n",
    "    <p>[그림03_04]</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf51c3f5",
   "metadata": {},
   "source": [
    "#### 인용출처\n",
    "[1] R을 활용한 기계학습, 브레드란츠, 전철욱, 에이콘, 164p ~169p를 참고, 데이터마이닝 기법 비교 연구: 단일 및 복수 의사결정나무, 신은주, 장남식, 363p를 참고<br>\n",
    "[2] R을 활용한 기계학습, 브레드란츠, 전철욱, 에이콘, 164p ~165p를 참고, 파이썬 머신러닝 완벽 가이드, 권민철, 위키북스, 183p 참고<br>\n",
    "[3] 자료구조(2018),조행래,영남대학교,K-Mooc, 8강 트리와 이진 트리의 개념 강의자료 2-6page를 인용하여 재구성함.<br>(http://contents.kocw.or.kr/KOCW/document/2016/cup/weonsumghyun/8.pdf)<br>\n",
    "[4] 이산수학(2016),원성현,부산가톨릭대학교,KOCW  8강 트리 강의자료 3-4page를 인용하여 재구성함.(http://contents.kocw.or.kr/KOCW/document/2016/cup/weonsumghyun/8.pdf)\n",
    "[5] 파이썬을 활용한 머신러닝: 사이킷런 핵심 개발자가 쓴 머신러닝과 데이터 과학 실무서(2018),박해선,김태현,한빛미디어, 101 ~102page 참고하여 재구성함.\n",
    "\n",
    "#### 참고문헌\n",
    "1. R을 활용한 기계학습, 브레드란츠, 전철욱, 에이콘\n",
    "2. 자료구조(2018),조행래,영남대학교,K-Mooc (http://www.kmooc.kr/courses/course-v1:YeungnamUnivK+YU216002+2018_01/about)<br>\n",
    "3. 이산수학(2016),원성현,부산가톨릭대학교,KOCW http://www.kocw.net/home/cview.do?cid=2df3e8cf09399ca3\n",
    "4. 파이썬을 활용한 머신러닝: 사이킷런 핵심 개발자가 쓴 머신러닝과 데이터 과학 실무서, \n",
    "\n",
    "#### 이미지 출처\n",
    "\n",
    "[그림03_01],[그림03_02] : 의사결정나무 차트(https://scikit-learn.org/stable/modules/tree.html#tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e848a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
