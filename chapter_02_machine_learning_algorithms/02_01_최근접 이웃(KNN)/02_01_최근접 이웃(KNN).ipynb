{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ef2867",
   "metadata": {},
   "source": [
    "## 02.최근접 이웃(KNN : K Nearest Neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e048636",
   "metadata": {},
   "source": [
    "## (1) KNN 이해하기\n",
    "옛말에 \"유유상종\"<span style=\"font-size:70%\">[1]</span>이기 때문에 \"그 사람을 알려면 그가 사귀는 친구를 보라\"<span style=\"font-size:70%\">[2]</span> 라는 말이 있다. 서로 비슷한 사람들이 끼리끼리 어울려 다니며 사귀는법이기 때문에 어울리는 무리를 통해 그 사람에 대해서 판단해볼만 하다는 이야기이다. 이는 KNN알고리즘의 작동 방식과 정확하게 일치한다. \n",
    "\n",
    "KNN은 어떤 미지의 데이터에 대하여 가장 근접한 데이터의 라벨을 그 데이터의 정체로 판단하는 지도학습 분류(Classification) 알고리즘을 말한다. \n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_01.png?raw=true\" width=600>\n",
    "    <p>[그림201]</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d1a9ed",
   "metadata": {},
   "source": [
    "## (2) KNN의 작동원리\n",
    "\n",
    "KNN은 어떤 미지의 라벨을 분류하는 **지도학습** 방식의 알고리즘이기 때문에, 분류하고자 하는 정답값이 존재하는 라벨링이 된 데이터를 모델학습에 활용한다.\n",
    "\n",
    "KNN은 학습시 별도의 복잡한 과정 없이 훈련데이터 모두를 N차원상의 벡터공간의 한 점(벡터)으로 메모리에 저장하고 학습을 마무리한다. 아래 그림처럼 총 10개의 관측값이 존재하는 라벨링된 데이터를 학습할 경우 10개의 점을 N차원상의 한 점으로 맵핑할 뿐이다.\n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_02.png?raw=true\" width=700>\n",
    "\t<p>[그림202]</p>\n",
    "</div>\n",
    "\n",
    "그리고 분류할 데이터도 마찬가지로 훈련데이터와 같은 벡터공간의 벡터로 맵핑하고, 사전에 맵핑시킨 모든 벡터와 거리를 비교한다.\n",
    "\n",
    "그 후 가장 가까운 K개만큼의 벡터를 추출해 그 중 다수결 원칙에 따라 분류를 진행한다.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <p align=\"center\">[그림203]</p>\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_03.png?raw=true\" width=400>\n",
    "\t\n",
    "</div>\n",
    "\n",
    "그렇기 때문에 K의 수에 따라 모델이 분류하는 결과값이 달라질 수 있으며, 보통은 K값의 동률을 방지하기 위해 홀수로 설정하며, 만약 동률이 발생할 경우 무작위 혹은 각 점의 거리가 짧은 순으로 판단한다.\n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_04.png?raw=true\" width=600>\n",
    "\t<p>[그림204]</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d657cd",
   "metadata": {},
   "source": [
    "## (3)KNN 알고리즘 더 깊게 이해하기\n",
    "\n",
    "### KNN 알고리즘의  특징\n",
    "KNN은 단순히 데이터를 N차원상의 벡터공간의 한 점으로 저장하고, 비교하여 예측값을 제공할 뿐이기 때문에 [01.머신러닝의 이해](https://github.com/int29/PMLP-101/blob/main/chapter_01_Understanding_Machine_Learning/01.%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0.md) 에서 머신러닝의 학습에 대해 설명했던 추상화와 일반화 과정이 없는 모형이다. 이렇게 모델을 만들지 않고 단순히 각 데이터를(인스턴스) 저장하였다 활용하는 알고리즘을 인스턴스 베이스 머신러닝 알고리즘이라고 하고, KNN은 인스턴스 베이스 모델중 한가지 이다.<span style=\"font-size:70%\">1</span>,<span style=\"font-size:70%\">2</span> \n",
    "\n",
    "KNN은 학습과정에서 추상화를 통해 데이터의 패턴을 계산하고 미지의 데이터에 대해서도 잘 반영할 수 있는 모델을 만드는 일반화 과정 없이 단순히 벡터공간상의 한 점으로 맵핑하여 학습을 진행하기 때문에 모델 베이스 머신러닝에 비해서 훈련속도가 빠르다. \n",
    "\n",
    "또한 간단한 알고리즘이기 때문에 하이퍼 파라미터가 적어 개발 및 파라미터 튜닝과정 또한 상대적으로 빨리 모델을 개발할 수 있다. \n",
    "\n",
    "마지막으로 로직이 직관적이기 때문에 가장 처음 생성하고 살펴보는 베이스모형(혹은 벤치마크모형)에 많이 사용하곤한다.\n",
    "\n",
    "반면 분류하려는 값에 대하여 모든 훈련 인스턴스와 비교를 진행하기 때문에 훈련속도는 빠르지만 예측(분류)하는 속도는 모델 베이스 모형보다 느리다. 또 두 벡터 사이의 거리를 계산하는 방식으로 이상치나 잡음, 데이터 피처(Feature)의 스케일에 영향을 많이 받는다는 단점이 존재한다. 또한 적절 K를 선정하는것이 어렵다. \n",
    "\n",
    "### KNN의 거리계산 방식\n",
    "KNN은 거리가 가까울수록 유사도가 높고, 거리가 멀수록 유사도가 낮다는 굉장히 심플한 논리를 갖고 있다. 따라서 KNN은 벡터(좌표평면의 한 점)끼리의 거리를 계산하여 얼마나 유사한지 유사도를 계산한다. 거리 계산 시 가장 많이 사용하는 방법은 유클리디안 거리(Euclidean distance) 계산 방식으로 중학교 수학에 나오는 피타고라스의 정리와 계산방법이 동일한 거리계산 법이다. \n",
    "\n",
    "> 유클리디안 거리(Euclidean distance)는 유클리드가 선형대수에서는 L2 norm이라고 부르는 벡터간 최단거리를 계산하는 방법이다. 세분화된 분야에 따라서 부르는 명칭은 다르지만 계산하는 방식은 모두 동일하다.\n",
    "\n",
    "유클리디안 거리(Euclidean distance) 는 아래와 같이 계산한다.\n",
    "\n",
    "$$d(p,q) = \\sqrt{\\sum_{i=1}^n (q_i - p_i)^2} =  \\sqrt{(x_1 - x_2)^2+(y_1 - y_2)^2+...+(u_1 - u_2)^2} $$\n",
    "$d(p,q)$는 두 점 $p$와 $q$ 사이의 거리를 나타내고, $n$은 차원의 수를 나타냄. $u$는 N번째 차원의 축을 의미함\n",
    "\n",
    "예를 들어 x축과 y축 2개의 축을 갖는 2차원상의 두 점(벡터) $p$와 $q$는 각각 $(x_1, y_1)$, $(x_1, y_2) = (1, 2), (3, 4)$ 이라는 좌표를 갖는다고 해보자.  두 점 $p$와 $q$는 아래와 같이 좌표계에 표현이 가능할 것이다.\n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_05.png?raw=true\" width=400>\n",
    "\t<p>[그림205]</p>\n",
    "</div>\n",
    "\n",
    "이 때 두 점사이의 최단거리는 두점의 직선거리가 되기 때문에 \n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_06.png?raw=true\" width=400>\n",
    "\t<p>[그림206]</p>\n",
    "</div>\n",
    "\n",
    "유클리디안 거리 계산 공식에 대입하면 두 점사이의 거리가 $2$ 임을 계산할 수 있다.\n",
    "$$d(p,q) =\\sqrt{(1 - 3)^2+(2 - 4)^2}= \\sqrt{(-2)^2+(-2)^2} = \\sqrt{4} = 2$$\n",
    "\n",
    "이를 쉽게 생각하면 아래와 같은 삼각형의 대각선의 거리와 동일한 모양이 나온다. 따라서 피타고라스의 정리를 적용하면 동일한 결과가 나오는것을 알 수 있다.\n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_07.png?raw=true\" width=400>\n",
    "\t<p>[그림207]</p>\n",
    "</div>\n",
    "\n",
    "> 거리를 계산하는 방법이나, 유사도를 계산하는 방법은 맨하튼 거리(L1 norm), 코사인유사도($\\theta$)(cosin distance), 두 점사이의 상관관계를 활용하는 마할라노비스 거리(Mahalanobis distance) 등 여러 방법이 존재한다. 각 방법의 장단이 존재하고 사용해야하는 상황이 각기 다르기 때문에 추후에 꼭 각 거리의 계산법과 장단점들을 공부하길 바란다.<span style=\"font-size:70%\">[3]</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2a10c",
   "metadata": {},
   "source": [
    "## (4) KNN데이터 활용해보기\n",
    "\n",
    "Iris 데이터는 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)' 총 4개의 피처(features)로 구성돼 있다. 이번 챕터는 위에서 설명한 KNN모형에 대해서 활용과 함께 이해하는 것이 목표이기 때문에 우선 'petal length (cm)', 'petal width (cm)' 2개의 피처로 KNN모형을 만들어 실제 KNN알고리즘이 어떻게 작동하는지 확인하고 4개의 모든 피처로 iris의 class를 분류(예측)하는 완성된 KNN모형을 만들것이다.\n",
    "\n",
    "\n",
    "사용하는 Iris 데이터의 설명과 전처리 및 EDA에 대한내용은 분량 및 구성상 [예제 데이터 설명 : iris 데이터]() 에 설명해 두었으니, 본 예제를 진행하기 전 꼭 확인후에 알고리즘 활용을 살펴보길 바란다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa036f",
   "metadata": {},
   "source": [
    "### Step00 : 라이브러리 로드\n",
    "pure python을 통해서 A부터 Z까지 개발하는건 아니기 때문에 데이터를 핸들링하는 pandas, numpy 라이브러리, 시각화를 도와주는 matplotlib, seaborn, KNN모델을 만들 수 있는 sklearn라이브러리를 로드한다.\n",
    "\n",
    "사용하는 라이브러리는 아래와 같고 설치가 필요할 경우 아래 명령어를 통해 설치하도록 하자.\n",
    "1. 데이터 전처리를 위한 pandas 및 numpy 라이브러리, 데이터 시각화를 위한 라이브러리 matploblib, seaborn\n",
    "    * `pip install pandas, numpy, matploblib, seaborn` <br><br>\n",
    "2. sklearn 머신러닝 라이브러리\n",
    "    * `pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5c15c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리를 위한 pandas 및 numpy 라이브러리 로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn 머신러닝 라이브러리에서 iris 예제 데이터 로드하는 함수 로드\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# sklearn KNN 로드\n",
    "from sklearn import neighbors\n",
    "\n",
    "# sklearn Train&Test Set나누는 함수 로드\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sklearn 평가(metric)함수 중 accuracy 점수 로드\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# warnning message를 노출하지 않는 설정\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 주피터 노트북에 차트를 바로 랜더링하기 위한 주피터노트북 내장 매직명령어\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd4030",
   "metadata": {},
   "source": [
    "### Step01 : 데이터 로드 및 클린징(전처리)\n",
    "\n",
    "라이브러리를 로드하였다면, Iris데이터를 로드하고 데이터프레임형태로 전처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b33e612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris 데이터로드 및 처리\n",
    "iris_data = load_iris()\n",
    "\n",
    "# iris 피처데이터 값, 피처 칼럼명, 타겟 데이터값, 타겟값의 각 class의 이름 로드\n",
    "# 해당 과정에 대한 자세한 설명은 [예제 데이터 설명 : iris 데이터]를 참고\n",
    "\n",
    "features = iris_data['data'] # iris데이터에서 피쳐들의 값을 추출\n",
    "column_name = iris_data['feature_names'] # iris데이터에서 피쳐칼럼명을 추출\n",
    "\n",
    "target = iris_data['target'] # iris데이터에서 타겟 칼럼값을 추출\n",
    "target_name = iris_data['target_names'] #타겟값의 각 class의 이름 로드\n",
    "\n",
    "# python dictionry 형태의 iris데이터를 pandas데이터프레임으로 변환\n",
    "iris_df = pd.DataFrame(features, columns= column_name)\n",
    "\n",
    "# 추출한 타겟값을 target이라는 칼럼명으로 추가\n",
    "iris_df['target'] = target\n",
    "\n",
    "# 0,1,2 코드형태로 저장된 타켓값을 알맞게 'setosa', 'versicolor', 'virginica'에 맞는 신규칼럼생성\n",
    "iris_df['target_names'] = ''\n",
    "iris_df['target_names'][iris_df['target']==0] = iris_data['target_names'][0]\n",
    "iris_df['target_names'][iris_df['target']==1] = iris_data['target_names'][1]\n",
    "iris_df['target_names'][iris_df['target']==2] = iris_data['target_names'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f51d7770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target target_names  \n",
       "0       0       setosa  \n",
       "1       0       setosa  \n",
       "2       0       setosa  \n",
       "3       0       setosa  \n",
       "4       0       setosa  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 head 체크\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47d5ef8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target target_names  \n",
       "145       2    virginica  \n",
       "146       2    virginica  \n",
       "147       2    virginica  \n",
       "148       2    virginica  \n",
       "149       2    virginica  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 head 체크\n",
    "iris_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e4576",
   "metadata": {},
   "source": [
    "### Step02 : 모델 훈련을 위한 데이터 준비\n",
    "### KNN의 직관적 이해를 위한 샘플데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32b3ebde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "41                 4.5               2.3                1.3               0.3   \n",
       "112                6.8               3.0                5.5               2.1   \n",
       "35                 5.0               3.2                1.2               0.2   \n",
       "47                 4.6               3.2                1.4               0.2   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "\n",
       "     target target_names  \n",
       "41        0       setosa  \n",
       "112       2    virginica  \n",
       "35        0       setosa  \n",
       "47        0       setosa  \n",
       "14        0       setosa  \n",
       "135       2    virginica  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개의 샘플을 랜덤으로 추출하여 sampled_train에 저장\n",
    "# 참고 : random_state는 시스템이 랜덤으로 뽑는 seed를 고정해서 여러번 수행해도 같은 결과가 노출될 수 있도록 고정한다.\n",
    "#987654\n",
    "sampled_train = iris_df.loc[(iris_df.target_names == \"setosa\")|(iris_df.target_names == \"virginica\")].sample(6, random_state=987654)\n",
    "sampled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81a18ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "116                6.5               3.0                5.5               1.8   \n",
       "\n",
       "     target target_names  \n",
       "116       2    virginica  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1개의 샘플을 랜덤으로 추출하여 sampled_test에 저장\n",
    "# 98765\n",
    "sampled_test = iris_df.loc[(iris_df.target_names == \"setosa\")|(iris_df.target_names == \"virginica\")].sample(1,random_state=123457)\n",
    "sampled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d06d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 피쳐 + 타겟으로 분리\n",
    "# 이번 예제에서 피처는 'petal length (cm)', 'petal width (cm)' 2개를 사용할 예정이다.\n",
    "\n",
    "# 'petal length (cm)', 'petal width (cm)'만 선택하여 훈련데이터 생성\n",
    "X_train = sampled_train[['sepal length (cm)', 'sepal width (cm)']]\n",
    "y_train = sampled_train['target_names']\n",
    "\n",
    "# 'petal length (cm)', 'petal width (cm)'만 선택하여 테스트이터 생성\n",
    "X_test = sampled_test[['sepal length (cm)', 'sepal width (cm)']]\n",
    "y_test = sampled_test['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af4785",
   "metadata": {},
   "source": [
    "### 훈련+테스트 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71c1a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련데이터\n",
    "sns.scatterplot(data=sampled_train, x=\"sepal length (cm)\", y=\"sepal width (cm)\", hue=\"target_names\", palette=['blue','red'])\n",
    "\n",
    "# 테스트데이터\n",
    "sns.scatterplot(data=sampled_test, x=\"sepal length (cm)\", y=\"sepal width (cm)\", hue=\"target_names\", palette=['black'], legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc1f8e",
   "metadata": {},
   "source": [
    "### Step03 : 모델 훈련 및 예측결과\n",
    "만들어낸 샘플 데이터를 통해 KNN 모델을 생성하고 예측한 결과는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f75bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1일 때, 테스트데이터에 대한 KNN의 예측결과는 ['virginica'] 입니다.\n"
     ]
    }
   ],
   "source": [
    "# estimater 생성 (모델 생성, k=1~5까지)\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=n, metric=\"euclidean\")\n",
    "\n",
    "# 모델 훈련(train data)(보통 feeding 이라고 부름: 데이터를 먹인다)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 타켓값이 없는 X_test를 통해 테스트셋에 대한 예측\n",
    "pred = clf.predict(X_test)\n",
    "print(f\"K={n}일 때, 테스트데이터에 대한 KNN의 예측결과는 {pred} 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f2624",
   "metadata": {},
   "source": [
    "### K값에 따라 달라지는 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c56b3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1일 때, 테스트데이터에 대한 KNN의 예측결과는 ['virginica'] 입니다.\n",
      "K=2일 때, 테스트데이터에 대한 KNN의 예측결과는 ['virginica'] 입니다.\n",
      "K=3일 때, 테스트데이터에 대한 KNN의 예측결과는 ['virginica'] 입니다.\n",
      "K=4일 때, 테스트데이터에 대한 KNN의 예측결과는 ['setosa'] 입니다.\n",
      "K=5일 때, 테스트데이터에 대한 KNN의 예측결과는 ['setosa'] 입니다.\n"
     ]
    }
   ],
   "source": [
    "# estimater 생성 (모델 생성, k=1~5까지)\n",
    "for n in range(1,6):\n",
    "    \n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=n, metric=\"euclidean\")\n",
    "\n",
    "    # 모델 훈련(train data)(보통 feeding 이라고 부름: 데이터를 먹인다)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # 타켓값이 없는 X_test를 통해 테스트셋에 대한 예측\n",
    "    pred = clf.predict(X_test)\n",
    "    print(f\"K={n}일 때, 테스트데이터에 대한 KNN의 예측결과는 {pred} 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458a72b",
   "metadata": {},
   "source": [
    "위 결과에 대해서 직관적으로 해석해보면 다음과 같은데, K의 값에 따른 KNN모델의 훈련을 시각화 하면 아래와 같을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56033a3",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\t<img src=\"https://github.com/int29/PMLP-101/blob/main/chapter_02_Algorithm_Classification_01_KNN/img/02_17.png?raw=true\">\n",
    "\t<p>[그림207]</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845a663",
   "metadata": {},
   "source": [
    "여기서 K=4인 경우 `setosa`, `virginica` 인스턴스가 각각 2개로 동률(tie)인데, Sklearn은 동률일 경우 target 라벨의 소팅 순서대로 결과를 내보내기 때문에 `setosa`로 예측한다.)\n",
    "\n",
    ">원문 : Warning Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor k+1 and k, have identical distances but different labels, the results will depend on the ordering of the training data.[\\[4\\]](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "### KNN 하이퍼파라미터와 하이퍼파라미터 튜닝&최적화\n",
    "\n",
    "머신러닝에는 사용자가 정해줘야하는 값인 하이퍼 파라미터라는 값이 존재한다. 이 하이퍼 파라미터를 어떻게 결정하느냐에 따라 좋은결과를 얻을 수도, 과적합이나 과소적합된 모형을 만들 수 있기 때문에 모델의 훈련정확도를 올리고 테스트데이터에 대한 일반화 정도를 높이기 위해 하이퍼 파라미터 튜닝하는 과정이 필수적으로 요구된다. \n",
    "sklearn 라이브러리의 neighbors.KNeighborsClassifier( ) 는 아래와 같이 사용자가 정해주어야할 하이퍼파라미터가 존재한다. \n",
    "\n",
    "    KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None\n",
    "\n",
    "전체 하이퍼파라미터 및 함수인자는 [공식문서](\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\") 에서 확인 가능하다. 여기서는 neighbors.KNeighborsClassifier의 주요한 하이퍼파라미터가 의미하는 바와 어떻게 영향을 미치는지 확인해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2888250",
   "metadata": {},
   "source": [
    "### 1) n_neighbors=5 : K의 수 (기본값 5)\n",
    "n_neighbors의 경우 위 예시에서 확인했듯, K의 수이다. K개만큼 이웃을 추출하여 타겟값을 예측한다. (단, K개는 전체 훈련 인스턴스의 수 이상으로 설정할 수 없다.)\n",
    "\n",
    "여기서 중요한 부분은 K의 증가와 감소에 따른 모델이 어떻게 변화하는지인데, K가 작을경우 소수의 훈련인스턴스에 따라서 모델의 결과가 정해지기 때문에 모델은 과적합(Overfitting)될 가능성이 높다. 반대로 K가 증가할수록 점점 불필요한 이웃들이 포함될 가능성이 높아져 과소적합(Underfitting) 가능성이 올라간다. 위 예시에서 k가 5이상부터는 전체 훈련 데이터에 virginica가 2개밖에 되지 않기 때문에 무조건 setosa가 과반을 차지한다. 따라서 KNN모델은 setosa만 노출하게 돼 모델은 훈련데이터와 테스트데이터 모두를 반영하지 못하는 과소적합(Underfitting)상태가 된다.\n",
    "\n",
    "또한 동률일 경우 단지 setosa의 순서가 virinica보다 앞서 정렬되기 때문에 setosa가 노출되게 된다. 이처럼 짝수일 경우 동률(tie)문제가 발생할 수 있기 때문에 보통은 홀수로 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43944ba7",
   "metadata": {},
   "source": [
    "### 2) metric='minkowski' : 인스턴스간 거리 측정방식 (기본값 : minkowski)\n",
    "\n",
    "metric은 인스턴스간 거리를 어떻게 계산할지 설정하는 하이퍼 파라미터이다. 거리를 계산하는 방법이나, 유사도를 계산하는 방법은 맨하튼 거리(L1 norm), 코사인유사도(𝜃)(cosin distance), 두 점사이의 상관관계를 활용하는 마할라노비스 거리(Mahalanobis distance) 등 여러 방법이 존재한다. 각 방법의 장단이 존재하고 사용해야하는 상황이 각기 다르기 때문에 추후에 꼭 각 거리의 계산법과 장단점들을 공부가 필요하며[3] Sklearn의 KNN모델에서 지원하는 거리계산 방식은 [공식문서](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics) 에서 참고가 가능하다. \n",
    "\n",
    "특별한 경우가 아닌 매우 일반적인 상황에서는 `euclidean`을 주로 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf25407",
   "metadata": {},
   "source": [
    "### 3) weights='uniform' : 인스턴스의 중요도를 다르게 평가하기 (기본값='uniform')\n",
    "\n",
    "위 예시에서 K=4인 경우 동률이기 때문에 단지 ordering 으로 예측결과를 산출했다. KNN은 산술적으로 K개만큼 이웃 인스턴스를 추출하기 때문에 이러한 결과를 내보내는 것이다. 하지만 직관적으로 산점도를 살펴보면 검정색 테스트데이터는 붉은색 `virginica` 그룹에 더 가깝게 위치해있기 때문에 `virginica`로 판단하는게 더 합리적이게 보이는데 이렇게 각 인스턴스에 다른 가중치를 주는 하이퍼파라미터가 `weights` 이다. 기본값인 `uniform`은 모든 인스턴스를 동일하게 생각하겠다는 것이고, `distance`를 설정해 거리가 가까운 인스턴스를 더 중요하게 판단하게 모델훈련이 가능하다.(또는 사용자가 직접 명시한 가중치를 통해 각 인스턴스의 중요도를 설정가능하다)\n",
    "\n",
    "아래 `K=4`인 KNN모델에 `weights=\"distance\"`를 설정할경우 기존과 어떻게 달라지는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a22787cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=4일 때, 테스트데이터에 대한 KNN의 예측결과는 ['virginica'] 입니다.\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors=4, metric=\"euclidean\", weights=\"distance\")\n",
    "\n",
    "# 모델 훈련(train data)(보통 feeding 이라고 부름: 데이터를 먹인다)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 타켓값이 없는 X_test를 통해 테스트셋에 대한 예측\n",
    "pred = clf.predict(X_test)\n",
    "print(f\"K=4일 때, 테스트데이터에 대한 KNN의 예측결과는 {pred} 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a21daa",
   "metadata": {},
   "source": [
    "`weights=\"distance\"`로 하이퍼파라미터를 설정한 결과 `setosa`로 예측했던 과거와 달리 `virginica`로 올바르게 예측하는것을 확인할 수 있다. 이처럼 단지 모델개발을 한번하는것 외에도 머신러닝 모델을 개발할 때는 우리의 목표에 맞는 모델이 개발될 수 있도록 하이퍼파라미터를 튜닝하여 최적화하는 과정이 필수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1bb43",
   "metadata": {},
   "source": [
    "## (5) KNN 모델 예제 : 붖꽃(Iris) 품종 분류모델 개발\n",
    "\n",
    "Iris 데이터의 샘플을 통해 KNN에 대한 모델을 이해했다면, 이제는 전체 Iris데이터를 통해서 KNN 모델을 개발해보자 위 `Step00 : 라이브러리 로드`, `Step01 : 데이터 로드 및 클린징(전처리)`된 데이터를 계속 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b325d9f",
   "metadata": {},
   "source": [
    "### Step02 : 모델 훈련을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3512fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 피쳐 + 타겟으로 분리\n",
    "# 이번 예제에서 피처는 'petal length (cm)', 'petal width (cm)' 2개를 사용할 예정이다.\n",
    "\n",
    "# 'petal length (cm)', 'petal width (cm)'만 선택하여 훈련데이터 생성\n",
    "X = iris_df[['sepal length (cm)', 'sepal width (cm)']]\n",
    "\n",
    "# 타겟\n",
    "y = iris_df['target_names']\n",
    "\n",
    "# 모델을 학습할 데이터인 150송이 중 80%와 테스트할 20%를 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed91fda",
   "metadata": {},
   "source": [
    "### Step03 : 베이스 모델훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0bfae7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimater 생성 (모델 생성, k=1)\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# 모델 훈련(train data)(보통 feeding 이라고 부름: 데이터를 먹인다)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ee05b",
   "metadata": {},
   "source": [
    "### Step04 : 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b04a0241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor',\n",
       "       'setosa', 'setosa', 'setosa', 'versicolor', 'virginica',\n",
       "       'versicolor', 'setosa', 'virginica', 'virginica', 'setosa',\n",
       "       'virginica', 'versicolor', 'setosa', 'versicolor', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'versicolor', 'virginica',\n",
       "       'setosa', 'virginica', 'versicolor', 'virginica', 'setosa'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타켓값이 없는 X_test를 통해 테스트셋에 대한 예측\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# 예측값 확인\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ef7ec66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666666"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 값과 평가\n",
    "accuracy_score(pred, y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1731bd2",
   "metadata": {},
   "source": [
    "### Step05 : 하이퍼 파라미터 튜닝\n",
    "\n",
    "하이퍼 파라미터는 사용자가 직접 설정하는 값이기 때문에 \"어떤 값을 넣는것이 옳은가?\" 라는 의문이 들 수 있다. 하지만 애석하게도 `00.들어가기`에 설명했듯이 이건 The Art의 영역이기 때문에 정답이 없다. 내가 갖은 데이터, 머신러닝 Task에 따라 하이퍼파라미터값에 따른 모델의 점수를 살펴보며 하이퍼파라미터를 튜닝하게된다. 가장 쉬운 방법은 범위를 지정하고 그 범위에 맞는 모든 조합을 실행한 후 가장 점수가 좋은 하이퍼 파라미터를 사용하는 것이다.\n",
    "\n",
    "> 하이퍼 파라미터를 튜닝하고 최적화하는 과정을 최적화 이론에 따라서 튜팅이 가능하다. 한가지 예시로 모든 값을 실행해보는 grid search 방법외에 베이지안 최적화를 통해서 하이퍼파라미터를 튜닝할 수 있다.\n",
    "> * 베이지안 최적화 : bayes_opt 파이썬 라이브러리(https://github.com/fmfn/BayesianOptimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb5b23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=1, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=1, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=1, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=3, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=3, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=3, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=3, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=5, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=5, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=5, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 66.66666666666666 입니다.\n",
      "K=5, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=7, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=7, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 76.66666666666667 입니다.\n",
      "K=7, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=7, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 76.66666666666667 입니다.\n",
      "K=9, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=9, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=9, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n",
      "K=9, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 70.0 입니다.\n"
     ]
    }
   ],
   "source": [
    "# estimater 생성 (모델 생성, k=1)\n",
    "hyper_param_n_neighbors = [1,3,5,7,9]\n",
    "hyper_param_metric = [\"euclidean\",\"minkowski\"]\n",
    "hyper_param_weights = [\"distance\",\"uniform\"]\n",
    "\n",
    "for k in hyper_param_n_neighbors:\n",
    "    for param_metric in hyper_param_metric:\n",
    "        for param_weights in hyper_param_weights:\n",
    "            clf = neighbors.KNeighborsClassifier(n_neighbors=k, metric=param_metric, weights=param_weights) # 하이퍼 파라미터를 적용한 estimator 생성\n",
    "            clf.fit(X_train, y_train) # 모델 훈련\n",
    "            pred = clf.predict(X_test) # 예측\n",
    "            pred_score = accuracy_score(pred, y_test)*100 # 실제 값과 평가\n",
    "            \n",
    "            print(f\"K={k}, metric={param_metric}, weights={param_weights} 일 때, 테스트데이터에 대한 KNN의 예측정확도는 {pred_score} 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459955a",
   "metadata": {},
   "source": [
    "### Step06 : 피쳐 엔지니어링\n",
    "\n",
    "주요한 하이퍼파라미터를 모두 적용해보았지만, 성능의 유효한 향상이 없었다. 하이퍼파라미터 튜닝은 전체 모델에서 과적합을 막고 추가적인 정확도 확보할 수 있지만 만능은 아니다. 하이퍼 파라미터 튜닝 보다 사실 더 효과적인 방법은 훈련하는 데이터에 집중하는것이다. 우리는 훈련데이터에 들어가는 이러한 과정을 피쳐 엔지니어링이라고 한다. 피쳐 엔지니어링은 피쳐를 선택하는 feature selection 뿐만아니라 파생변수를 생성하는 Deriving features, PCA, T-SNE, Auto Encoding과 같이 피쳐 자체를 변경시키는 feature extraction(or feature transform) 과 같은 굉장히 광범위한 분야를 모두 포괄한다.\n",
    "\n",
    "어려운 부분들은 차차 진행하기로 하고, 지금은 피쳐선택(feature selection)을 진행해 모델의 성능을 높여보자\n",
    "모델에 사용한 피쳐는 'sepal length (cm)', 'sepal width (cm)' 2가지로 실제 iris데이터는 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)' 4가지 피쳐가 존재한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "812ea8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존  'sepal length (cm)', 'sepal width (cm)' 사용하던 피쳐에서 1개를 'petal length (cm)' 추가해보자\n",
    "X = iris_df[['sepal length (cm)', 'sepal width (cm)','petal length (cm)']]\n",
    "\n",
    "# 타겟\n",
    "y = iris_df['target_names']\n",
    "\n",
    "# 모델을 학습할 데이터인 150송이 중 80%와 테스트할 20%를 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "814d449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=3일 때, 테스트데이터에 대한 KNN의 예측결과는 90.0 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델훈련\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\", weights=\"distance\")\n",
    "\n",
    "# 모델 훈련(train data)(보통 feeding 이라고 부름: 데이터를 먹인다)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 타켓값이 없는 X_test를 통해 테스트셋에 대한 예측\n",
    "pred = clf.predict(X_test)\n",
    "pred_score = accuracy_score(pred, y_test)*100\n",
    "print(f\"K=3일 때, 테스트데이터에 대한 KNN의 예측결과는 {pred_score} 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ce0c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=1, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=1, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=1, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=3, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=3, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=3, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=3, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=5, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=5, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=5, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=5, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=7, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=7, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=7, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=7, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=9, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=9, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=9, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=9, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝\n",
    "hyper_param_n_neighbors = [1,3,5,7,9]\n",
    "hyper_param_metric = [\"euclidean\",\"minkowski\"]\n",
    "hyper_param_weights = [\"distance\",\"uniform\"]\n",
    "\n",
    "for k in hyper_param_n_neighbors:\n",
    "    for param_metric in hyper_param_metric:\n",
    "        for param_weights in hyper_param_weights:\n",
    "            clf = neighbors.KNeighborsClassifier(n_neighbors=k, metric=param_metric, weights=param_weights) # 하이퍼 파라미터를 적용한 estimator 생성\n",
    "            clf.fit(X_train, y_train) # 모델 훈련\n",
    "            pred = clf.predict(X_test) # 예측\n",
    "            pred_score = accuracy_score(pred, y_test)*100 # 실제 값과 평가\n",
    "            \n",
    "            print(f\"K={k}, metric={param_metric}, weights={param_weights} 일 때, 테스트데이터에 대한 KNN의 예측정확도는 {pred_score} 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547ac12",
   "metadata": {},
   "source": [
    "하이퍼파라미터 튜닝까지 해서 100% 정확도를 달성했다. 그렇다면 4개 모든 피쳐를 사용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7355ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존  'sepal length (cm)', 'sepal width (cm)' 사용하던 피쳐에서 1개를 'petal length (cm)' 추가해보자\n",
    "X = iris_df[['sepal length (cm)', 'sepal width (cm)','petal length (cm)','petal length (cm)']]\n",
    "\n",
    "# 타겟\n",
    "y = iris_df['target_names']\n",
    "\n",
    "# 모델을 학습할 데이터인 150송이 중 80%와 테스트할 20%를 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c38d49eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=1, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=1, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=1, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=3, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=3, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=3, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=3, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 90.0 입니다.\n",
      "K=5, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=5, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=5, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=5, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=7, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=7, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=7, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 93.33333333333333 입니다.\n",
      "K=7, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=9, metric=euclidean, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=9, metric=euclidean, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=9, metric=minkowski, weights=distance 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n",
      "K=9, metric=minkowski, weights=uniform 일 때, 테스트데이터에 대한 KNN의 예측정확도는 100.0 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝\n",
    "hyper_param_n_neighbors = [1,3,5,7,9]\n",
    "hyper_param_metric = [\"euclidean\",\"minkowski\"]\n",
    "hyper_param_weights = [\"distance\",\"uniform\"]\n",
    "\n",
    "for k in hyper_param_n_neighbors:\n",
    "    for param_metric in hyper_param_metric:\n",
    "        for param_weights in hyper_param_weights:\n",
    "            clf = neighbors.KNeighborsClassifier(n_neighbors=k, metric=param_metric, weights=param_weights) # 하이퍼 파라미터를 적용한 estimator 생성\n",
    "            clf.fit(X_train, y_train) # 모델 훈련\n",
    "            pred = clf.predict(X_test) # 예측\n",
    "            pred_score = accuracy_score(pred, y_test)*100 # 실제 값과 평가\n",
    "            \n",
    "            print(f\"K={k}, metric={param_metric}, weights={param_weights} 일 때, 테스트데이터에 대한 KNN의 예측정확도는 {pred_score} 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c8555",
   "metadata": {},
   "source": [
    "단지 `petal length (cm)` 또는 `petal length (cm), petal length (cm)`를 추가한것으로 20%이상의 정확도가 향상되었다. 머신러닝은 data science의 일종으로 데이터가 주인공이다. 좋은 모델과 모델튜닝도 중요하지만 제일 중요한건 데이터임을 잊어서는 안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa83a0",
   "metadata": {},
   "source": [
    "\n",
    "### 인용\n",
    "\n",
    "<span style=\"font-size:70%\">[1]</span> : 네이버 국어사전(https://ko.dict.naver.com/#/entry/koko/dcc68b744c1b410dae38939990808f7c) \n",
    "\n",
    "<span style=\"font-size:70%\">[2]</span> :  不知其人이어든 視其友하라 (http://www.hanjanews.com/news/articleView.html?idxno=3650)\n",
    "> 不知其子이어든 視其父하고 不知其人이어든 視其友하라.\n",
    "> [독음]부지기자 시기부 부지기인 시기우[해석] 그 아들을 모르겠거든 그 아비를 보고 그 사람을 모르겠거든 그 친구를 보라\n",
    "\n",
    "<span style=\"font-size:70%\">[3]</span> : 데이터 과학을 위한 통계 : 데이터 분석에서 머신러닝까지 50가지 핵심개념(2018), 피터 브루스, 앤드루 브루스, 이준용, 김태헌, 한및미디어, 242p \n",
    "><원문>\n",
    ">벡터사이의 거리를 측정하기 위해 수많은 거리 지표들이 있다. 수치 데이터를 다룰 때, 마할라비스 거리 Mahalanobis distance는 두 변수 간의 상관관계를 사용하기 때문에 .... <후략>\n",
    "\n",
    "<span style=\"font-size:70%\">[4]</span> : sklearn 공식홈페이지 문서 (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "><원문>Warning Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor k+1 and k, have identical distances but different labels, the results will depend on the ordering of the training data.\n",
    "\n",
    "### 미주\n",
    "<span style=\"font-size:70%\">1</span> : 반대로 추상화와 일반화 과정을 거쳐 특정 모형을 생성하여 학습후 해당 모형을 통해 예측하는 모형을 모델 베이스 머신러닝(model based machine learning)이라 부른다. 이러한 모델 베이스 머신러닝은 특정 구조의 모형을 가정하고, 그 성질을 파라미터로 표현하는 존재하는 parametric 모형과 특정 구조의 모형을 가정하지 않는  모형인 non-parametric모형 중 어떤 모형을 활용하는지에 따라  parametric machine learning 과 non-parametric machine learning 으로 분류한다. \n",
    "\n",
    "<span style=\"font-size:70%\">2</span> : 또는 게으른 학습(Lazy learning) 알고리즘이라고도 부른다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
