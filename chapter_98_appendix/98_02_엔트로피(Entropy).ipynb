{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c041553b",
   "metadata": {},
   "source": [
    "## 98_02. 정보 엔트로피(Information Entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd013f2",
   "metadata": {},
   "source": [
    "정보 엔트로피는 정보량을 비트(bit)의 개념을 통해 수학적으로 표현하고 측정하는 이론으로 1948년 벨 연구소의 클로드 섀넌Claude Shannon은 “A mathematical theory of communication”이라는 제목의 논문을 발표한 이론을 말한다. [8]\n",
    "\n",
    "> 전화선으로 얼마나 많은 정보가 전달되는지 수치화 할 수 있을까?[9]\n",
    "\n",
    "> 정보의 가치를 그저 감성적으로 이해하던 것을 1945년경 미국의 섀넌(Shannon)은 정보의 가치를 엔트로피(entropy)라는 것으로 계량화하였다. 어떤 정보의 엔트로피란 주어진 정보를 될 수 있는 데로 압축하여 0과 1로 표현할 때 필요한 비트 수이다. 엔트로피를 통하여 정보를 질량이나 에너지, 운동량과 같은 수량화된 물리량으로 만들었다. [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae2dec",
   "metadata": {},
   "source": [
    "### 비트를 활용한 정보 표현과 정보량의 측정\n",
    "특정 정보를 0과 1로만 2진수로 표현할 수 있는데, 이를 비트 표현방법이라고 한다. 예를 들어 동전의 앞면을 0 뒷면을 1로 정하고 동전던지기의 결과를 전달한다고 해보자. 따라서 앞이나오면 0을 뒤가 나오면 1로만 전달하면 되기 때문에 0,1로만 전달이 가능하다. 따라서 동전 1개의 결과는 1 bit의 정보량을 갖는다.\n",
    "\n",
    "그렇다면 공정한 동전 2개를 던질경우 어떻게 표현이 가능할까? 나올 수 있는 모든 사건의 경우의 수를 0과 1로 표현해보면 아래와 같이 4가지=$2^2$로 표현이 가능하고 4가지 사건에 대해 설명하기 위해서는 정보량이 2 bit가 필요한것을 알 수 있다.\n",
    "\n",
    "    [앞,앞]: 11\n",
    "    [앞,뒤]: 10\n",
    "    [뒤,앞]: 01\n",
    "    [뒤,뒤]: 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9bb86",
   "metadata": {},
   "source": [
    "즉 각 경우의 수를 2의 제곱근으로 표현하면 비트(bit)로 표현이 가능한 것이다. 이는 사건이 발생할 수 있는 총 경우의수를 2의 n 제곱근으로 표현하면 해당 사건이 갖는 총 비트의수를 계산할 수 있는것이다. 따라서 특정확률 $p$를 갖는 어떤 사건을 비트로 표현한다면 $-log_{2}{p}$가 되는것이다. \n",
    "> 왜 로그를 취하는지 의문점이 들 수 있는데 $log_{2}{4}=2$ 라는 의미는 2를 몇 제곱해야지 4가 되는지에 대한 표기이기 때문에 답은 자연스래 2가된다. 즉 $log_{2}{p}$는 2를 몇 제곱해야지 $p$가 나오는지를 구하는 $log_{2}{p}=2^{x}=p$인 $x$를 구하는 것과 동일한 계산이다. 또 확률은 분수이고 로그를 통해 분수를 계산할 경우 음수가 자연스럽게 나오기 때문에 -값을 취해 비트를 양의 값으로 변환해 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f53e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "389ff25d",
   "metadata": {},
   "source": [
    "따라서 동전 1개와 동전 2개일때의 비트(bit)표현을 다시 계산해본다면\n",
    "* 동전 1개 앞면이 나올 확율이= $p=\\frac{1}{2}$ 일때, 앞면이 나타난 사건을 비트로 표현하면\n",
    "$$bit=-log_{2}{\\frac{1}{2}}=1$$ \n",
    "이 되고 뒷면 또한 뒷면 또한 확률= $p=\\frac{1}{2}$  이기 때문에 \n",
    "$$bit=-log_{2}{\\frac{1}{2}}=1$$ 이 된다.\n",
    "\n",
    "* 동전 2개 앞앞인 사건을 나타내기 위해서는 $p=\\frac{1}{4}$ 라면\n",
    "$$bit=-log_{2}{\\frac{1}{4}}=2$$ \n",
    "* 이 되고 앞뒤인 나타내기 위해서는 = $p=\\frac{1}{4}$  이기 때문에 \n",
    "$$bit=-log_{2}{\\frac{1}{4}}=2$$ \n",
    "* 이 되고 뒤앞인나타내기 위해서는= $p=\\frac{1}{4}$  이기 때문에 \n",
    "$$bit=-log_{2}{\\frac{1}{4}}=2$$ \n",
    "* 이 되고 뒤뒤인 나타내기 위해서는= $p=\\frac{1}{4}$  이기 때문에 \n",
    "$$bit=-log_{2}{\\frac{1}{4}}=2$$ \n",
    "\n",
    "각각 2bit가 필요한것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9c421",
   "metadata": {},
   "source": [
    "### 엔트로피(Entropy)\n",
    "\"엔트로피($I_{E}$)는 특정 메시지의 기대 비트수를 의미한다. 이후 나올 예시에서 왜 값자기 확률에 비트를 곱하는지는 아래 예시를 통해서 이해해보자.\n",
    "\n",
    "<기대값>\n",
    "눈금의 수가 1 부터 6까지 존재하는 정육면체 주사위가 있다. 주사위는 조작 없이 공평하며 각 눈금이 나올 확률은 모두 $\\frac{1}{6}$으로 동일하다. 이 때 주사위를 던졌을 때 나오는 눈금의 기대값는? \n",
    "\n",
    "$$1\\cdot \\frac{1}{6}+1\\cdot \\frac{1}{6}+2\\cdot \\frac{1}{6}+3\\cdot \\frac{1}{6}+4\\cdot \\frac{1}{6}+5\\cdot \\frac{1}{6}+6\\cdot \\frac{1}{6} = 3.5$$\n",
    "\n",
    "즉 주사위를 던지면 3.5라는 눈금은 없지만, 나오는 눈금을 종이에 기록했을 때 그 평균이 3.5정도 된다는 것이다. 따라서 기대 비트값은 특정확률에서 몇 비트가 나올것인가를 계산한것이기 때문에 비트를 확률에 곱하게 된다.\n",
    "\n",
    "즉 동전1개 던지기의 엔트로피($I_{E}$)는 앞면이 1 뒷면이 1 이기 때문에 필요한 비트수는 1\n",
    "\n",
    "우리가 대화하는 글속에서 가장 많이 등장하는 자음은 무엇일까? \n",
    "\n",
    ">표 3은 한국어의 자음을 기준으로 사용빈도별 글자수를 보여주는 것이다. 총 사용빈도수는 3,368,465로서 “ㄷ”열이 사용빈도가 725,586로서 사용 빈도 율이 전 체의 22%로서 가장 많고다음이 “ㅇ”열 순으로 사용 빈도 율이 전체의 15%로 나타났다. 사용빈도율이 가장 ....[11]\n",
    "\n",
    "이처럼 자음의 경우 동전던지기와 다르게 다른 출현빈도를 갖는것을 알 수 있다. 즉 각각의 자음마다 등장 확률이 다르다는 뜻이된다. 동전던지기는 모두 같은 확률이었지만, 자음은 모두 다른 확률이다. \n",
    "\n",
    "이를 확률적으로 표현하면 특정 확률분포를 갖는 경우 해당사건의 기대 비트수는 몇인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da7ed6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*1/6+2*1/6+3*1/6+4*1/6+5*1/6+6*1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d5aea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db519bc8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a800c9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2b7c387",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49e128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c084c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
